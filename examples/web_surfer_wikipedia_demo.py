#!/usr/bin/env python3
"""
Wikipedia Web Surfer Demo

This example demonstrates complex web interactions with Wikipedia using the WebSurfer
implementation with browser-use integration.

Features demonstrated:
1. Navigation to Wikipedia
2. Search functionality
3. Article navigation
4. Content extraction from Wikipedia articles
5. Following links and exploring related content

Requirements:
- OpenAI API key (set OPENAI_API_KEY environment variable)
- Browser-use library (included in thirdparty/)
"""

import asyncio
import os
import sys
from typing import List

from pydantic import BaseModel

# Add project root to path
sys.path.append(os.path.join(os.path.dirname(__file__), "../.."))

import logging

from cogents.core.base.llm import get_llm_client
from cogents.core.base.logging import setup_logging
from cogents_wiz.web_surfer import WebSurfer

# Setup logging
setup_logging()
logger = logging.getLogger(__name__)
llm_client = get_llm_client(provider="openrouter", instructor=True)


class WikipediaArticle(BaseModel):
    """Schema for extracting Wikipedia article data"""

    title: str
    summary: str
    main_sections: List[str]
    categories: List[str]


async def demo_wikipedia_search():
    """Demonstrate Wikipedia search functionality."""
    logger.info("üîç Demo: Wikipedia Search")

    web_surfer = WebSurfer(llm_client=llm_client)

    try:
        page = await web_surfer.launch(headless=False)

        # Navigate to Wikipedia
        await page.navigate("https://en.wikipedia.org")
        logger.info("‚úÖ Successfully navigated to Wikipedia")

        # Search for "Artificial Intelligence"
        search_result = await page.act("Search for 'Artificial Intelligence' using the search box")
        logger.info(f"‚úÖ Search completed: {search_result}")

        # Wait a moment for the page to load
        await asyncio.sleep(2)

    finally:
        await web_surfer.close()


async def demo_wikipedia_article_extraction():
    """Demonstrate extracting structured data from Wikipedia articles."""
    logger.info("üìä Demo: Wikipedia Article Extraction")

    web_surfer = WebSurfer(llm_client=llm_client)

    try:
        page = await web_surfer.launch(headless=False)

        # Navigate directly to an AI article
        await page.navigate("https://en.wikipedia.org/wiki/Machine_learning")
        logger.info("‚úÖ Successfully navigated to Machine Learning article")

        # Extract structured information from the article
        article_data = await page.extract(
            instruction="Extract the article title, first paragraph summary, main section headings, and categories",
            schema=WikipediaArticle,
        )

        logger.info("‚úÖ Extracted article data:")
        if isinstance(article_data, WikipediaArticle):
            logger.info(f"  Title: {article_data.title}")
            logger.info(f"  Summary: {article_data.summary[:200]}...")
            logger.info(f"  Main sections: {', '.join(article_data.main_sections[:5])}")
            logger.info(f"  Categories: {', '.join(article_data.categories[:3])}")
        else:
            logger.info(f"  Raw data: {article_data}")

    finally:
        await web_surfer.close()


async def demo_wikipedia_navigation():
    """Demonstrate navigating between Wikipedia articles."""
    logger.info("üß≠ Demo: Wikipedia Navigation")

    web_surfer = WebSurfer(llm_client=llm_client)

    try:
        page = await web_surfer.launch(headless=False)

        # Start at Python programming language article
        await page.navigate("https://en.wikipedia.org/wiki/Python_(programming_language)")
        logger.info("‚úÖ Started at Python programming language article")

        # Click on a link to explore related content
        navigation_result = await page.act(
            "Click on the first link in the 'See also' section or find a link related to 'machine learning' or 'data science'"
        )
        logger.info(f"‚úÖ Navigation result: {navigation_result}")

        # Wait for navigation
        await asyncio.sleep(2)

        # Extract information about the new page
        page_info = await page.act("Tell me what Wikipedia article we're currently viewing and provide a brief summary")
        logger.info(f"‚úÖ Current page info: {page_info}")

    finally:
        await web_surfer.close()


async def demo_wikipedia_comparison():
    """Demonstrate comparing information from multiple Wikipedia articles."""
    logger.info("‚öñÔ∏è Demo: Wikipedia Article Comparison")

    web_surfer = WebSurfer(llm_client=llm_client)

    try:
        page = await web_surfer.launch(headless=False)

        # Visit first article: Machine Learning
        await page.navigate("https://en.wikipedia.org/wiki/Machine_learning")
        ml_info = await page.act(
            "Extract the key definition and main applications of machine learning from this article"
        )
        logger.info(f"‚úÖ Machine Learning info: {ml_info}")

        # Visit second article: Deep Learning
        await page.navigate("https://en.wikipedia.org/wiki/Deep_learning")
        dl_info = await page.act("Extract the key definition and main applications of deep learning from this article")
        logger.info(f"‚úÖ Deep Learning info: {dl_info}")

        # Compare the two
        logger.info("üìù Comparison completed - in a real application, you could now analyze the differences")

    finally:
        await web_surfer.close()


async def demo_wikipedia_autonomous_research():
    """Demonstrate autonomous research on Wikipedia."""
    logger.info("ü§ñ Demo: Autonomous Wikipedia Research")

    web_surfer = WebSurfer(llm_client=llm_client)

    try:
        # Create autonomous agent for Wikipedia research
        agent = await web_surfer.agent(
            prompt="""Go to Wikipedia and research 'Natural Language Processing'. 
            Find the main article, read the introduction, and then explore one related topic 
            by clicking on a relevant link. Summarize what you learned about both topics.""",
            use_vision=True,
            max_failures=2,
            max_actions_per_step=3,
        )

        # Run the research agent
        result = await agent.run()
        logger.info(f"‚úÖ Research completed: {result}")

    finally:
        await web_surfer.close()


async def run_wikipedia_demos():
    """Run all Wikipedia demonstration functions."""
    logger.info("üöÄ Starting Wikipedia WebSurfer Demo")

    try:
        # Run demos with delays to manage rate limits
        await demo_wikipedia_search()
        await asyncio.sleep(2)  # Brief pause between demos

        await demo_wikipedia_article_extraction()
        await asyncio.sleep(2)

        await demo_wikipedia_navigation()
        await asyncio.sleep(2)

        await demo_wikipedia_comparison()
        await asyncio.sleep(2)

        # Skip autonomous demo initially to avoid rate limits
        logger.info("ü§ñ Skipping autonomous research demo to manage rate limits")
        logger.info("    To enable it, uncomment the autonomous demo call below")
        # await demo_wikipedia_autonomous_research()

        logger.info("üéâ All Wikipedia demos completed successfully!")

    except Exception as e:
        logger.error(f"‚ùå Demo failed: {e}")
        raise


def main():
    """Main entry point."""
    try:
        asyncio.run(run_wikipedia_demos())
    except KeyboardInterrupt:
        logger.info("üëã Demo interrupted by user")
    except Exception as e:
        logger.error(f"‚ùå Demo failed with error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
